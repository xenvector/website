{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Deployment","text":""},{"location":"#deployment","title":"Deployment","text":""},{"location":"#sorte-dilapsa-veniam-roganti-undas-tum-ab","title":"Sorte dilapsa veniam roganti undas tum ab","text":"<p>Lorem markdownum. Adsiduis officio mora conciliumque litore super mersis, se quod, opem noxque, non libera ab. Infra opus peregit non. Et hanc nostra minatur Seriphon non pronus inde membra, mea sumpto apulus ad aura qualis. Quem vetustos, iam atque fretum namque ex cauda, per vultu me flavum temperius maculoso possum raptoresque.</p> <p>Perspice et equo fulgura, aut gaudet sunt dumque niveum, fugitque abstrahor saxis fulmineis est esse. Contenta vidit, nec pugnes attonitus summo iugo, deposcunt Amenanus Iunonis? Quaesitamque motae nec: terras heros semper nuper, et inpono gradus, ab.</p>"},{"location":"#amictus-polenta-carina-admirantibus-faciat","title":"Amictus polenta carina admirantibus faciat","text":"<p>Tum quae convicia studiis: faxo cunas visa clarus, quondam, prius. Novi nata dedit, Poemenis trementi haruspex prodere fontem: e. Nova nubes bracchia aras squamas moraque ad segetes remoto.</p> <pre><code>&gt; Modo dira nostroque congreditur patria si corpus insidior illam lusibus per\n&gt; vim relinquunt talia. Per an supremo gaudet latices *Melaneus* latuerunt tibi\n&gt; petebar, Pirithoi spectacula. Et hectora limina, quaeque, hoc adde precor\n&gt; domosque, sed in dieque, me pinnis desunt, cadunt. Nam fallacis isto talia\n&gt; tenues inferiusque non solito hic matre? Mirum at licet qui cuncta collo\n&gt; [deductus](http://www.fraude-ignipedum.io/) animoque quoque.\n</code></pre> <p>Tamen tenebras sit vacuas ire fecerat deus reddidit sonantia, mite sorores, surrexit removente iussa et, ne. Verba malorum Lycias tempestiva irae ex mentes illo durasse Proteus genitore habes; Phoebes doloris, et rara.</p>"},{"location":"#sum-ait-othrysque-hoc-unum-convexa-hinc","title":"Sum ait Othrysque hoc unum convexa hinc","text":"<p>Inque inmurmurat at prodere: o viri corpora nuper, ut calido certa cum. Ilios enim iam iniustaque fonti, ab torva. Auro precor solebat vincla septemplice ultra errore crescens nomina dextraque annis praetemptatque carpitque protinus dextra, exanimem, fatentis. Maris rates, et fugant et pia aera rumpere arces laesasque, ira silvas quem ministri variatis Cerberon videntem si.</p> <p>Aureus in tellus deplanxere facti se tuus sive, cecidere quisque, variare pulsatus. Non in gentesque funera sufficiunt detractare illo perlucentibus atlas vel reperta non insula.</p> <p>Noctis tamen. Ora facta armo montis iussae Busirin in flammae inanes.</p> <p>Pia fuerunt movit, terra turba mentis quem cinis cladem, madidum labor ponit clavam. Imo vitamque: diem cum ore intravit pro filia Aiax.</p>"},{"location":"blog/","title":"Articles","text":""},{"location":"blog/2024/07/02/graphrag/","title":"GraphRAG","text":""},{"location":"blog/2024/07/02/graphrag/#enhancing-intelligent-applications-using-graphrag","title":"Enhancing Intelligent Applications using GraphRAG","text":"<p>In today's rapidly evolving enterprise landscape, leveraging large language models (LLMs) to build AI-driven operations and intelligent applications is crucial for success. With the rise of private data sets within organizations, it becomes essential to establish clear relationships between various datasets using LLMs and Knowledge Graphs</p> <p> </p>LLMs vs Knowledge Graphs <p> A prime example that highlights this need would be an incident management platform requiring a thorough understanding of error events and performance events to make accurate service circuit SLA decisions. Likewise, in enterprise security information and event management (SIEM) systems, correlating user identities with their access paths from logs is essential to identify anomalies effectively. The significance of using LLMs for these purposes has gained momentum through discussions within the research community. One such platform that embodies this approach is Microsoft's GraphRAG (Graph-based RAGnometries), which was announced in February 2024. GraphRAG offers an AI-driven content interpretation and search capability by utilizing LLMs to create a knowledge graph from private datasets, enabling users to query the data effectively for better results.</p>"},{"location":"blog/2024/07/02/graphrag/#graphrag-advantages","title":"GraphRAG Advantages","text":"<p>The major advantage of using Microsoft's GraphRAG over traditional vector search techniques is its ability to handle complex queries that demand higher order reasoning or extensive comprehension of the dataset at hand. For instance, when asked \"What are the most unusual conversations?\" a conventional vector search may fall short if it doesn't find an exact match in the data set. In contrast, GraphRAG builds a knowledge graph based on semantic concepts and provides a holistic understanding of all sources, allowing users to discover relevant information at various levels of abstraction for more accurate retrieval-augmented generation tasks.</p> <p></p> <p>Google Cloud has similar GraphRAG implementation using Neo4J </p> <p>GraphRAG can be employed across critical information discovery and analysis use cases where datasets span multiple documents or contain noise, mixed with misinformation, or when the user's queries are abstract or thematic in nature. Furthermore, it is designed to complement a domain expert's analytical approach rather than replace their insights altogether.</p> <p>The GraphRAG process begins by indexing an input corpus into analyzable TextUnits and extracting entities, relationships, and key claims using LLMs. This information undergoes hierarchical clustering via the Leiden technique to create a visual graph representation of entities. From there, summaries are generated for each community and its constituents from bottom-up, enabling users to gain comprehensive insights into their dataset.</p> <p>When querying GraphRAG's knowledge graph, users can employ two primary modes: global search for holistic questions about the corpus or local search for specific entities by exploring related concepts within their neighborhood. It is worth noting that fine-tuning prompts using Microsoft's Prompt Tuning Guide may be necessary to achieve optimal results when working with your data set.</p>"},{"location":"blog/2024/07/02/graphrag/#architecture","title":"Architecture","text":"Architecture diagram shows how Google Cloud and Neo4j work together to build and interact with knowledge graphs <ul> <li> <p>Knowledge extraction - On the left side of the diagram, blue arrows show data flowing from structured and unstructured sources into Vertex AI. Generative AI is used to extract entities and relationships from that data which are then converted to Neo4j Cypher queries that are run against the Neo4j database to populate the knowledge graph. This work was traditionally done manually with handcrafted rules. Using generative AI eliminates much of the manual work of data cleansing and consolidation.</p> </li> <li> <p>Knowledge consumption - On the right side of the diagram, green arrows show applications that consume the knowledge graph. They present natural language interfaces to users. Vertex AI generative AI converts that natural language to Neo4j Cypher that is run against the Neo4j database. This allows non technical users to interact more closely with the database than was possible without generative AI</p> </li> </ul>"},{"location":"blog/2024/07/02/graphrag/#usecases","title":"UseCases","text":"<p>We\u2019re seeing this architecture come up again and again across verticals. Some examples include:</p> <ul> <li> <p>Healthcare - Modeling the patient journey for multiple sclerosis to improve patient outcomes</p> </li> <li> <p>Manufacturing - Using generative AI to collect a bill of materials that extends across domains, something that wasn\u2019t tractable with previous manual approaches</p> </li> <li> <p>Oil and gas - Building a knowledge base with extracts from technical documents that users without a data science background can interact with. This enables them to more quickly educate themselves and answer questions about the business.</p> </li> </ul>"},{"location":"capability/aiops/","title":"AIOPS Deck.","text":""},{"location":"capability/aiops/#aiops-deck","title":"AIOPS Deck.","text":""},{"location":"capability/appmodern/","title":"App Modernization Deck.","text":""},{"location":"capability/appmodern/#app-modernization-deck","title":"App Modernization Deck.","text":""},{"location":"capability/brochure/","title":"Full Capability Deck.","text":""},{"location":"capability/brochure/#full-capability-deck","title":"Full Capability Deck.","text":""},{"location":"capability/datamesh/","title":"DataMesh Deck.","text":""},{"location":"capability/datamesh/#datamesh-deck","title":"DataMesh Deck.","text":""},{"location":"capability/security/","title":"Security Services Deck.","text":""},{"location":"capability/security/#security-services-deck","title":"Security Services Deck.","text":""},{"location":"blog/category/genai/","title":"GENAI","text":""}]}